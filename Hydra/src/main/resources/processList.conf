mail = {
  to: ${?val_mail_to}
  from: ${?val_mail_from}
  smtp: {
   host: ""
   port: "25"
   starttls.enable: "true"
   starttls.required: "true"
   ssl.trust: ""
   send.partial: "true"
   }
}

hydra-spark-preprocessor={
 name: "hydra-spark-preprocessor"
 type: "com.ms.ci.hydra.data.pipeline.preprocessor.HydraPreProcessor"
 params: {
    is_s3_enabled: ${val_is_s3_enabled}
 }
}

hydra-data-loader={
 name: "hydra-data-loader"
 type: "com.ms.ci.hydra.data.pipeline.loader.DBDataLoader"
 params: {

 }
}

hydra-rule-engine={
 name: "hydra-rule-engine"
 type: "com.ms.ci.hydra.data.pipeline.ruleengine.EPPMatcher"
 params: {

 }
}

db2-sink={
 name: "db2-sink"
 type: "com.ms.ci.hydra.data.pipeline.sinks.DB2Sink"
 params: {

 }
}

recon-validator={
 name: "recon-validator"
 type: "com.ms.ci.hydra.data.pipeline.validator.ReconValidator"
 params: {

 }
}

hydra-post-processor={
 name: "hydra-post-processor"
 type: "com.ms.ci.hydra.data.pipeline.postprocessor.HydraPostProcessor"
 params: {

 }
}

hydra-shutdown-hook={
 name: "hydra-shutdown-hooks"
 type: "com.ms.ci.hydra.data.pipeline.shutdownhook.HydraShutdownHooks"
 params: {

 }
}



additionalSparkConf={
    spark.hadoop.fs.s3a.impl: "org.apache.hadoop.fs.s3a.S3AFileSystem"
    spark.hadoop.fs.s3a.multipart.size: "104857600"
    spark.hadoop.fs.s3a.thread.core: "10"
    spark.hadoop.fs.s3a.thread.max: "16"
    spark.hadoop.fs.s3a.lock.size: "33554432"
    spark.hadoop.fs.s3a.path.style.access: "true"
    spark.hadoop.mapreduce.fileoutputcommitter.algorithm.version: "2"
}